The importance of eigenvalues in mathematics and physics is well established. For very large matrices, however, computing all eigenvalues can be prohibitively expensive. In many applications, it suffices to know only a few extremal eigenvalues, certain functionals of the eigenvalues, or the overall distribution of eigenvalues, leading to the concept of the spectral density.

The spectral density, as defined below, provides an exact representation of the eigenvalue distribution. Because it is formulated using the Dirac delta distribution, which is not a conventional function, it must be regularized for practical computations. While efficient techniques exist for real symmetric matrices, our aim is to extend these ideas to the unitary case. To do so, we first revisit Hermitian matrices, introduce the Cayley transform as a link to unitary matrices, and then develop the spectral density framework for unitary matrices. This foundation enables us to address the main algorithm.

\section{Unitary Matrices}

We begin with a basic definition of real symmetric matrices, which we then extend to the complex case. The superscript~$^T$ denotes the transpose of a matrix, while~$^*$ indicates the~\emph{conjugate transpose}, also called the~\emph{adjoint}, obtained by taking the transpose and then complex conjugating all entries. As is common in the literature, $I_n$ denotes the identity matrix of size~$n$.

\begin{definition}[Symmetric matrix]
    Let $A \in \R^{n \times n}$ be a real, square matrix of size~$n$. Then $A$ is called~\emph{symmetric} if~$A^T = A$.
\end{definition}
\noindent
This concept can be naturally extended from real matrices to the complex case.

\begin{definition}[Hermitian matrix]
    Let $A \in \C^{n \times n}$ be a complex square matrix of size~$n$. Then~$A$ is called~\emph{Hermitian} if~$A^* = A$.
\end{definition}
\noindent
Throughout this thesis,~$A$ denotes a complex, square matrix of size~$n$, unless stated otherwise. When referring to a Hermitian matrix, we use the letter~$H$.

For an examination of the eigenvalues of a Hermitian matrix, let~$H = H^* \in \C^{n \times n}$ and~$H v = \lambda v$ for a complex vector~$v \in \C^n \setminus \{\mathbf{0}\}$ and a scalar~$\lambda \in \C$. Consider now the inner product~$ v^* v$. With~$(A B)^* = B^* A^*$ and obviously~${(A^*)^*} = A$ we have that

\[
    \lambda v^* v = v^* \left( \lambda v \right)
    = v^* \left( H v \right)
    = \left(v^* H \right) v
    = \left( H^* v \right)^* v
    = \left( H v \right)^* v
    = (\lambda v)^* v
    = \overline{\lambda} v^* v.
\]
Since we required that~$v \neq \mathbf{0}$, it follows that~$v^* v \neq \mathbf{0}$ and therefore we can divide the equation by the inner product to obtain~$\lambda = \overline{\lambda}$, that is to say~$\lambda$ is real. This means that all eigenvalues of Hermitian matrices are real numbers. It follows that all eigenvalues of symmetric matrices are also real numbers, since they are a special case of Hermitian matrices.

We now introduce the types of complex matrices that play a central role in this thesis.

\begin{definition}[Unitary matrix]
    A matrix~$A \in \C^{n \times n}$ is called~\emph{unitary} if it satisfies~$A^* A = A A^* = I_n$.
\end{definition}
\noindent
The real analogue of a unitary matrix is an~\emph{orthogonal matrix}, which is defined by the condition $A^T A = A A^T = I_n$. We oftentimes denote unitary matrices by using~$U$ as a reference.

Consider a unitary matrix~$U$ and an eigenpair~$(\lambda, v)$ of~$U$. The complex conjugate of the eigenvalue equation~$U v = \lambda v$ is

\[
    v^* U^* = v^* \overline{\lambda} = \overline{\lambda} v^*.
\]
Again, we calculate the inner product
\[
    v^* v = v^* I_n v = v^* U^* U v = v^* \overline{\lambda} \lambda v = \overline{\lambda} \lambda v^* v = \left| \lambda \right|^2 v^* v.
\]
With the identical argument as above, we can divide by~$v^* v$ to obtain

\[
    1 = \left| \lambda \right|^2 \implies \left| \lambda \right| = 1,
\]
meaning that all eigenvalues of unitary matrices have a length of~$1$ and are thus situated on the unit circle. As they are a special case of unitary matrices, the same goes for orthogonal matrices. This property is crucial, as it enables the application of the Cayley transform, introduced in the following section.

There is a special group of matrices that all the matrices we have defined so far belong to.

\begin{definition}[Normal matrix]
    A matrix~$A \in \C^{n \times n}$ is called~\emph{normal} if it commutes with its conjugate transpose,
    that is to say~$A^* A = A A^*$.
\end{definition}
\noindent
It is straightforward to see that both Hermitian and unitary matrices are normal matrices and that the notion includes real symmetric and orthogonal matrices as special cases. The spectral theorem states that normal matrices can be diagonalized by a unitary matrix~\cite[Thm.~7.24, p.~218]{sheldonaxler}. That means, for any normal matrix~$A$, there exists a unitary matrix~$U$ such that~$A = U \Lambda U^*$, where~$\Lambda = \diag(\lambda_1, \ldots, \lambda_n)$ is a diagonal matrix with~$\lambda_1, \ldots, \lambda_n$ being the eigenvalues of~$A$. This is essential for applying a function to a matrix, which is discussed in the next section.

\section{Cayley Transform}

To proceed, we extend the concept of functions to normal matrices, which allows us to map one matrix to another.

\begin{definition}[Matrix function of normal matrices] \label{def:matrix_function}
Let~$A \in \C^{n \times n}$ be a normal matrix and let~$f: \C \to \C$ be a function that is defined on the spectrum of~$A$, that is, the set of its eigenvalues $\sigma(A) = \{\lambda_1, \ldots, \lambda_n\}$, where each~$\lambda_j$ is an eigenvalue of~$A$. Then the~\emph{matrix function}~$f(A)$ is defined as
\[
f(A) := f(U \Lambda U^*) = U f(\Lambda) U^* = U \diag(f(\lambda_1), \ldots, f(\lambda_n)) U^*,
\]
where~$U$ is the matrix of eigenvectors of~$A$ and~$\Lambda = \diag(\lambda_1, \ldots, \lambda_n)$ is the diagonal matrix of eigenvalues.
\end{definition}

This definition is a special case of the more general definition of matrix functions via the Jordan canonical form given by Higham in~\cite[p.~3]{higham}. Another consequence of the spectral theorem is that for normal matrices, the Jordan canonical form is diagonal. Therefore, Higham's general definition reduces to the spectral decomposition used here.

This enables us to define the \emph{Cayley transform}, which we then use as a matrix function that establishes a correspondence between Hermitian and unitary matrices, allowing spectral properties to be translated between these two important classes.

For a complex number $z \in \mathbb{C}$ with $z \neq -i$, the Cayley transform is defined as
\[
\varphi(z) = \frac{i - z}{i + z}.
\]
This function maps the real line to the unit circle in the complex plane.
\vspace{0.5cm}
\input{Graphics/cayley_transform.tex}
\noindent
The Cayley transform is a bijection from the complex plane without the point~$-i$ to the unit circle, and it is continuous and differentiable everywhere except at~$-i$. This specifically implies it being an involution, meaning that applying it twice returns the original value, i.e.,~$\varphi(\varphi(z)) = z$ for all~$z \in \mathbb{C} \setminus \{-i\}$.

Let us apply the Cayley transform to Hermitian matrices. According to Definition~\ref{def:matrix_function}, for a Hermitian matrix~$H$ with spectral decomposition~$H = U \Lambda U^*$, the Cayley transform as a matrix function is given by
\begin{align*}
    \varphi(H) = U \, \diag(\varphi(\lambda_1), \ldots, \varphi(\lambda_n)) \, U^* & = U \, \diag\left(\frac{i - \lambda_1}{i + \lambda_1}, \ldots, \frac{i - \lambda_n}{i + \lambda_n}\right) \, U^*\\
    & = U (i I_n - \Lambda) (i I_n + \Lambda)^{-1} U^*\\
    & = U (i I_n - \Lambda) U^* U (i I_n + \Lambda)^{-1} U^*\\
    & = (i I_n - H) \left( i I_n + H \right)^{-1}
\end{align*}
This calculation also illustrates that $(i I_n - H)$ and $(i I_n + H)^{-1}$ commute, or more precisely, 
\[
(i I_n - H)(i I_n + H)^{-1} = (i I_n + H)^{-1}(i I_n - H),
\]
as they are both products of the same unitary matrix~$U$ and diagonal matrices, which all commute with each other. Consequently, the interpretation of~$\frac{1}{i + z}$ as a scalar or matrix function does not affect the result, since the order of multiplication is immaterial in this context.

We have obtained an explicit formula which yields a unitary matrix~$V$ from a Hermitian matrix~$H$, given that~$i I_n + H$ is invertible. The Cayley transform for a Hermitian matrix is thus defined as
\[
V = \varphi(H) = (i I_n - H)(i I_n + H)^{-1}.
\]
The condition of~$i I_n + H$ being invertible is the same as requiring that~$H$ does not have~$-i$ as an eigenvalue. If (and only if) that were the case, we had~$Hv=-iv$ for some eigenvector~$v \neq \mathbf{0}$, and therefore
\[
(i I_n + H) v = i I_n v + H v = i v + (-i v) = 0.
\]
Since Hermitian matrices only have real eigenvalues as discussed above,~$-i$ can never be an eigenvalue. Conversely, given a unitary matrix~$U \neq -I_n$, the inverse Cayley transform yields a Hermitian matrix~$H$ as follows:
\[
H = i (I_n - U)(I_n + U)^{-1}.
\]
This is relevant later, as we can then use~$\varphi$ to transform unitary matrices into Hermitian ones and vice versa.

The Cayley transform is not only of theoretical interest; it has been successfully applied in efficient numerical algorithms for eigenvalue problems, see for example~\cite{aurentzmachvandebrilwatkins} and~\cite{meerbergenspenceroose}.

\section{Spectral Density}

To get to the notion of the spectral density, we first need some more basic definitions to build on.
The reader is assumed to be familiar with the concepts of distributions. Should that not be the case,~\cite{strichartz} gives a comprehensive introduction in his first chapter. Let us also recap that for~$\Omega \subset \R$ open and non-empty, a~\emph{test function} is a smooth function with compact support defined on~$\Omega$. The space of all test functions on~$\Omega$ is usually denoted by~$\mathcal{E}$.

One of the most fundamental distributions in analysis, and central to the spectral density framework, is the Dirac delta.

\begin{definition}[Dirac delta distribution]
    Let~$\mathcal{E} = \Cinfty(\Omega)$ with~$0 \in \Omega \subset \R$.
    Then
    \[
    \delta: \mathcal{E} \to \R, \quad f \mapsto f(0) \quad \text{with} \quad \langle \delta, f \rangle := \delta(f) = f(0).
    \]
\end{definition}
\noindent
This distribution is often referred to as a function, although it is not a function in the classical sense. The Dirac delta is characterized by its defining property,
\[
\int\limits_{-\infty}^{\infty} f(x) \delta(x-a) \dx = \int\limits_{-\infty}^{\infty} f(x) \delta(a-x) \dx = f(a) \implies \int\limits_{-\infty}^{\infty} \delta(x-a) \dx = 1.
\]
This means that the Dirac delta distribution is zero everywhere except at the point~$a$, where it is~\emph{infinitely large}, such that the integral over it equals~$1$. With this, we now have all the tools we need to introduce the central concept of this thesis, the spectral density.

\begin{definition}[Spectral density]
    Let~$H \in \C^{n \times n}$ be Hermitian. For~$x \in \R$, the~\emph{spectral density}~$\phi(x)$ is defined as
    \[
    \phi(x) = \frac{1}{n} \sum_{j=1}^{n} \delta(x - \lambda_j),
    \]
    where~$\delta$ is the Dirac delta distribution and~$\lambda_j$ are the eigenvalues of~$H$ in non-descending order.
\end{definition}

The summation over the~$n$ eigenvalues of~$H$ creates a spike at each eigenvalue~$\lambda_j$, resulting in a distribution that is zero everywhere except at the eigenvalues of~$H$. The division by~$n$ ensures that the spectral density is normalized, meaning that the Lebesgue integral over the entire real line equals~$1$. This is an important property, as it allows us to interpret the spectral density as a probability density function.

In practice, since~$\phi(x)$ is defined using the Dirac delta distribution, it must be regularized to obtain a meaningful and computable expression. The details of this relaxation are discussed in the next chapter.

Lastly, we need the notion of the Schwartz space, which we will use as the space of test functions in the following sections.

\begin{definition}[Schwartz space over $\R$] \label{def:Schwartz_space}
    The \emph{Schwartz space} over $\R$ consists of all smooth functions $f$ that decay rapidly to zero as $|x|$ approaches infinity \cite{richtmyer}.
    Formally,
    \[
    \SR := \left\{f \in \Cinfty(\R) \mid \forall p, k \in \N_0: \sup_{x \in \R} \left| x^p f^{(k)}(x) \right| < \infty \right\}.
    \]
\end{definition}