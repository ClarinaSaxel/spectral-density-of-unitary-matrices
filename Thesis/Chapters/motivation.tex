\section{Motivation}
Calculating the spectral density of a matrix is trivial, when its eigenvalues are already known.
However, this is mostly not the case and calculating eigenvalues of very large matrices is time- and energy intensive.
At the same time, the DOS as a kind of probability density over the distribution of eigenvalues is of great interest in many fields.
Thus, there is a need for methods which approximate the spectral density at low cost.
The problem with this is that $\phi(t)$ the Delta distribution is not a \emph{function} as we know it,
that can be evaluated at each point.\\
A more intuitive idea would be to choose an intervall $I \in \R$ such that the spectrum of $A$, $\sigma(A)$, is a subset of $I$.
Now choose $k$ points $t_i$ in $I$, such that the intervall is divided in sub intervals:
$$\{t_i\}_{i = 1}^k \subset I \quad \text{mit} \quad \bigcup_{i = 1}^{k - 1} [t_i, t_{i+1}] = I$$
Now count the eigenvalues in every sub interval.
Then calculate the average value of $\phi(t)$ in every intervall with $\nu_{[a, b]}$ from equation \ref{eq:nu_a_b}.
The results is histograms, which with increasingly smaller subintervalls, that is to say bigger $k$ and $(t_{i+1} - t_i) \longrightarrow 0$, approach the spectral density.\\
To count the eigenvalues in the intervals, there is means like for example the Sylvestreschen Tr√§gheitssatz.
The details of this method are not part of this work,
it would be necessary to calculate a decomposition of $A - t_i I = LDL^T$ for all $t_i$ \cite{golubvanloan}.
We prefer a method in which $A$ is multiplied with vectors, which is in bigger dimensions.\\
For simplicity we are going to assume, that $A$ is szmmetric and real.
The extension to hermetian matrices is simple in comparison.