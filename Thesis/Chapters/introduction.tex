We begin this thesis by examining unitary matrices and their fundamental properties.
Then we revisit the Cayley transform to finally close in on the spectral density.
Upon this we should be well-equipped to proceed with the investigation afterwards.

\section{Unitary Matrices}

We first recall two definitions for important real matrices that we then extend to complex matrices.
The index $^T$ marks the transpose of a matrix.
As common in literature, $I_n$ denotes the identity matrix of size $n$.

\begin{definition}[Symmetric matrix]
    Let $A$ be a real, square matrix of size $n$.
    Then $A$ is called \emph{symmetric} if $A^T = A$.
\end{definition}

The following definition is for matrices with their transpose as their inverse.

\begin{definition}[Orthogonal matrix]
    Let $A$ be a real, square matrix of size $n$.
    Then $A$ is called \emph{orthogonal} if $A^T \cdot A = I_n$.
\end{definition}

The complex equivalent of a real symmetric matrix is a \emph{Hermitian matrix}.
Note that $A^*$ is \emph{conjugate transpose} of the matrix $A$ with all of its entries complex conjugated and transposed.

\begin{definition}[Hermitian matrix]
    Let $A$ be a complex square matrix of size $n$.
    Then $A$ is called \emph{Hermitian} if $A^* = A$.
\end{definition}

Throughout this thesis, $A$ will denote a complex, square matrix of size $n$,
unless stated otherwise.
To reference a Hermitian matrix, we will use the letter $H$.

We examine the eigenvalues of Hermitian matrices.

Let $H = H^*$ and $H v = \lambda v$ for a complex vector $v \neq \mathbf{0}$ of size $n$ and a scalar $\lambda \in \C$.
Consider now the inner product $ v^* v$.

\begin{equation} \label{eq:real_symmetric_inner_product}
    \lambda v^* v = v^* \left( \lambda v \right)
    = v^* \left( H v \right)
    = \left(v^* H \right) v
    = \left( H^* v \right)^* v
    = \left( H v \right)^* v
    = (\lambda v)^* v
    = \overline{\lambda} v^* v
\end{equation}

Since we have that $v \neq \mathbf{0}$ it follows that $v^* v \neq \mathbf{0}$
and therefore $\lambda = \overline{\lambda}$, that is to say $\lambda$ is real.
This means that all eigenvalues of Hermitian matrices are real numbers.
It follows that all eigenvalues of symmetric matrices are also real numbers,
since they are a special case of Hermitian matrices.
Now we can extend the definition of orthogonal matrices to complex matrices.

\begin{definition}[Unitary matrix]
    A matrix $A$ is called \emph{unitary} if $A^* \cdot A = I_n$.
\end{definition}

We will oftentimes denote unitary matrices by using $U$ as a reference.
It is easy to see that orthogonal matrices are a special case of unitary matrices,
since $A^T = A^*$ for all real matrices.\\
Consider a unitary matrix $U$ and an eigenpair $(\lambda, v)$ of $U$.
The complex conjugate of the eigenvalue equation $U v = \lambda v$ is

\begin{equation} \label{eq:eigenvalue_equation_complex_conjugate}
    v^* U^* = v^* \overline{\lambda} = \overline{\lambda} v^*
\end{equation}

We calculate

\begin{align*}
    v^* v = v^* U^* U v = v^* \overline{\lambda} \lambda v = \overline{\lambda} \lambda v^* v = \left| \lambda \right|^2 v^* v
\end{align*}

Similarly to above, we can divide by $v^* v$ to obtain

\begin{equation} \label{eq:unitary_eigenvalues}
    1 = \left| \lambda \right|^2 = \left| \lambda \right|
\end{equation}

meaning that all eigenvalues of unitary matrices have a length of $1$ and are thus situated on the unit circle.
As they are a special case of unitary matrices, the same goes for orthogonal matrices.
This property is crucial, as it enables the application of the Cayley transform,
introduced in the following section.

\section{Cayley Transform}

The Cayley transform establishes a correspondence between Hermitian and unitary matrices,
allowing spectral properties to be translated between these two important classes.

For a complex number $z \in \mathbb{C}$ with $z \neq -i$, the Cayley transform is defined as
\[
\varphi(z) = \frac{i - z}{i + z}.
\]

This function maps the real line to the unit circle in the complex plane.

\vspace{0.5cm}

\input{Graphics/cayley_transform.tex}

For matrices, the Cayley transform maps a Hermitian matrix $H$ (with $i + H$ invertible) to a unitary matrix $U$ via
\[
U = (i - H)(i + H)^{-1}.
\]
The condition of $i + H$ being invertible is the same as requiring that $H$ does not have $-i$ as an eigenvalue.
If (and only if) that were the case, then we had $H v = -i v$ for some eigenvector $v \neq \mathbf{0}$,
and therefore 
\[
(i + H) v = i v + H v = i v + (-i v) = 0.
\]

Luckily, we know that Hermitian matrices can only ever have real eigenvalues, so $-i$ can never be an eigenvalue.\\

Conversely, given a unitary matrix $U$ (with $U \neq -I_n$),
the inverse Cayley transform yields a Hermitian matrix:
\[
H = i (I_n - U)(I_n + U)^{-1}.
\]

This will be relevant later, as we can then use $\varphi$ to transform unitary matrices into symmetric ones and vice versa.
In particular, it enables the transfer of spectral density results,
which will be explored in the following sections.

\section{Spectral Density}

To get to the notion of the spectral density,
we will first need some more basic definitions to build on.

\begin{definition}[linear functional]
    Let $V$ be a vectorspace over a field $\K$. A \emph{linear functional} $T$ is a linear function $T: V \to \K$.
    The space over all linear functionals $V \mapsto \K$ is called the \emph{dual space} $V'$.
\end{definition}

A simple example for such a functional would be

\begin{equation} \label{eq:functional_example_simple}
    T: \Cinfty(\R) \to \R, \qquad f \mapsto f(0)
\end{equation}

A more special case is the integral.

\begin{equation} \label{eq:functional_example_integral}
    T_g: \Cinfty(\C) \to \C, \qquad f \mapsto \int\limits_{\C} g \cdot f \dx
\end{equation}

This definition leads to the concept of a distribution which was introduced to get a method to differentiate where differentiation in the classical sense is not possible.

\begin{definition}[distribution]
    Let $\emptyset \neq \Omega \subset \R^n$ be open.
    Let $\mathcal{E}$ be the space of \emph{test functions} over $\Omega$.
    A \emph{distribution} $T$ is a function $T: \mathcal{E} \to \C$ where for all
    $g, g_1, g_2, \{g_n\}_{n \in \N} \in \mathcal{E}$
    with $\lim\limits_{n \to \infty} g_n \to g$ it holds:
    $$T(g_1 + \lambda g_2) = T(g_1) + \lambda T(g_2) \quad \text{und}\quad \lim\limits_{n \to \infty} T(g_n) \to T(g)$$
\end{definition}

So, put shortly: A distribution $T$ is a continuous and linear functional on $\mathcal{E}$.
Now the path is clear to define the so called Dirac delta distribution

\begin{definition}[Dirac delta function]
    Let $\mathcal{E} = \Cinfty(\Omega)$ with $0 \in \Omega \subset \R^n$.
    Then
    $$\delta: \mathcal{E} \to \R, f \mapsto f(0) \quad \text{mit} \quad \delta(f) = \langle \delta, f \rangle = f(0)$$
\end{definition}

An important feature of this definition is:

$$\int\limits_{-\infty}^{\infty} f(x) \delta(x-a) \dx = \int\limits_{-\infty}^{\infty} f(x) \delta(a-x) \dx = f(a) \implies \int\limits_{-\infty}^{\infty} \delta(x-a) \dx = 1$$

This distribution is often misleadingly labled as a function inspite of being decidedly not that.\\
We can now finally define the spectral density.

\begin{definition} [spectral density]
    Let $A \in \R^{n \times n}$, $A^T = A$ and $A$ sparce.
    Then, the spectral density is defined as
    $$\phi(t) = \frac{1}{n} \sum_{j=1}^{n} \delta(t - \lambda_j)$$
    where $\delta$ is the delta distribution and $\lambda_j$ are the eigenvalues of $A$ in non-descending order.
\end{definition}

The number of eigenvalues in an intervall $[a, b]$ can then be expressed as follows:

\begin{equation} \label{eq:nu_a_b}
    \nu_{[a, b]} = \int\limits_a^b \sum_j \delta(t - \lambda_j) \dt \equiv \int\limits_a^b n \phi(t) \dt
\end{equation}

\begin{definition} [Schwartz-space over $\R$] \label{def:Schwartz space}
    The Schwartz-space over $\R$ contains all smooth functions $f$,
    which fall fast enough against $0$, when $|x|$ gets closer to $\infty$. \cite{richtmyer}
    In Formeln
    $$\SR(\R) := \left\{f \in \Cinfty(\R) \mid \forall p, k \in \N_0: \sup_{x \in \R} \left| x^pf^{(k)}(x)\right| < \infty \right\}$$
    Im Weiteren werde ich das Symbol $\SR$ als Abkürzung für $\SR(\R)$ benutzen,
    da sich diese Arbeit allein mit dem reellen Kontext befasst.
\end{definition}